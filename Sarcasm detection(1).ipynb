{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0ad780-d67e-480c-b68f-52d05368e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b7d725-3352-40cb-9fb0-3725a0e033f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_sarcastic                                           headline  \\\n",
      "0             1  thirtysomething scientists unveil doomsday clo...   \n",
      "1             0  dem rep. totally nails why congress is falling...   \n",
      "2             0  eat your veggies: 9 deliciously different recipes   \n",
      "3             1  inclement weather prevents liar from getting t...   \n",
      "4             1  mother comes pretty close to using word 'strea...   \n",
      "\n",
      "                                        article_link  \n",
      "0  https://www.theonion.com/thirtysomething-scien...  \n",
      "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
      "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
      "3  https://local.theonion.com/inclement-weather-p...  \n",
      "4  https://www.theonion.com/mother-comes-pretty-c...  \n"
     ]
    }
   ],
   "source": [
    "file_path= 'C:/Users/ASUS/Downloads/archive/Sarcasm_Headlines_Dataset_v2.json'\n",
    "data=[]\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64322470-56eb-4715-8d0f-1482eb963e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b01d2755-9db4-4215-a4ca-d3dd6460d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76bcf601-bdac-4a6a-bb21-8a6de5d6a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= set(stopwords.words('english'))\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def preprocess(text):\n",
    "    text= text.lower()\n",
    "    text=re.sub(r'[^a-z\\s]','',text)\n",
    "    tokens= nltk.word_tokenize(text)\n",
    "    cleaned= [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c103fa-ff6b-488a-9007-c9c8403aff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline  \\\n",
      "0  thirtysomething scientists unveil doomsday clo...   \n",
      "1  dem rep. totally nails why congress is falling...   \n",
      "2  eat your veggies: 9 deliciously different recipes   \n",
      "3  inclement weather prevents liar from getting t...   \n",
      "4  mother comes pretty close to using word 'strea...   \n",
      "\n",
      "                                    cleaned_headline  \n",
      "0  thirtysomething scientist unveil doomsday cloc...  \n",
      "1  dem rep totally nail congress falling short ge...  \n",
      "2            eat veggie deliciously different recipe  \n",
      "3       inclement weather prevents liar getting work  \n",
      "4  mother come pretty close using word streaming ...  \n"
     ]
    }
   ],
   "source": [
    "df['cleaned_headline']= df['headline'].apply(preprocess)\n",
    "print(df[['headline', 'cleaned_headline']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16532db7-dbfb-421f-89df-065e1566808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb0c4da-7ca1-4fae-90f4-51c574e34787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f7be32c-98ce-4240-b1a6-c9b4ffa89d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer= TfidfVectorizer(max_features=1000)\n",
    "X=vectorizer.fit_transform(df['cleaned_headline']).toarray()\n",
    "y= df['is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f15d2232-2a10-42aa-9940-cef4221818be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c757d042-84e7-401b-b5a4-f1f209bc1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "436e3b90-98b3-40e2-9e3f-ff03a3ba969a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.75      2995\n",
      "           1       0.73      0.67      0.70      2729\n",
      "\n",
      "    accuracy                           0.72      5724\n",
      "   macro avg       0.72      0.72      0.72      5724\n",
      "weighted avg       0.72      0.72      0.72      5724\n",
      "\n",
      "Accuracy: 0.7236198462613557\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d6dcbf7-8096-49f2-9875-3ef5c19b0248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75      2995\n",
      "           1       0.73      0.68      0.71      2729\n",
      "\n",
      "    accuracy                           0.73      5724\n",
      "   macro avg       0.73      0.73      0.73      5724\n",
      "weighted avg       0.73      0.73      0.73      5724\n",
      "\n",
      "Accuracy: 0.730083857442348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# Much faster for text data\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Results:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8df0ac0e-ac55-48b5-94d2-eeab344eddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.22      0.34       550\n",
      "           1       0.49      0.93      0.65       450\n",
      "\n",
      "    accuracy                           0.54      1000\n",
      "   macro avg       0.65      0.58      0.49      1000\n",
      "weighted avg       0.66      0.54      0.48      1000\n",
      "\n",
      "Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Try small K and fewer samples for speed\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train[:3000], y_train[:3000])  # smaller train set\n",
    "y_pred_knn = knn.predict(X_test[:1000])  # smaller test set\n",
    "\n",
    "print(\"KNN Results:\")\n",
    "print(classification_report(y_test[:1000], y_pred_knn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test[:1000], y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cd164c0-9a7e-4c93-a8a4-a28e7d7d4d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Model  Accuracy\n",
      "0   Naive Bayes  0.723620\n",
      "1    Linear SVM  0.730084\n",
      "2  KNN (subset)  0.540000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "# Naive Bayes\n",
    "nb_acc = accuracy_score(y_test, y_pred_nb)\n",
    "results.append([\"Naive Bayes\", nb_acc])\n",
    "\n",
    "# SVM\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "results.append([\"Linear SVM\", svm_acc])\n",
    "\n",
    "# KNN (subset)\n",
    "subset_size_test = 1000  # define again here\n",
    "knn_acc = accuracy_score(y_test[:subset_size_test], y_pred_knn)\n",
    "results.append([\"KNN (subset)\", knn_acc])\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\"])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "192e3b7d-8632-4df5-abf6-a8f6bb24c04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(svm, \"sarcasm_detector_model.pkl\")\n",
    "joblib.dump(vectorizer, \"sarcasm_vectorizer.pkl\")\n",
    "\n",
    "print(\"✅ Model and vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34cd7008-115c-4925-bb59-9ccfc7ec70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and vectorizer\n",
    "loaded_model = joblib.load(\"sarcasm_detector_model.pkl\")\n",
    "loaded_vectorizer = joblib.load(\"sarcasm_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfe97d83-4908-4f45-9211-60890999ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sarcasm(text):\n",
    "    processed_text = preprocess(text)\n",
    "    vec = loaded_vectorizer.transform([processed_text])\n",
    "    prediction = loaded_model.predict(vec)[0]\n",
    "    return \"Sarcastic\" if prediction == 1 else \"Not Sarcastic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "730dc108-5602-4d43-bf73-f17ffac77e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic\n",
      "Sarcastic\n"
     ]
    }
   ],
   "source": [
    "print(predict_sarcasm(\"It was good to wait in sunlight for 3 hr\"))\n",
    "print(predict_sarcasm(\"Scientists discovered a cure for cancer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e1ed3-7c7a-44e7-a5d2-4f806ee693e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f7de2b-4801-4de1-aa60-b3fbcd7f47e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
